{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Preprocessing Sanity check\n",
        "## Choose dataset, preprocessing method, and review results\n",
        "\n",
        "This notebook provides a unified interface to:\n",
        "1. Load data\n",
        "2. Choose a preprocessing method (basic, **Llama**, or **Gemini API**)\n",
        "3. **Test with a small sample first** (NUM_SAMPLES = 5)\n",
        "4. Review and compare results\n",
        "5. Run on full dataset when satisfied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Python 3.8 compatibility shim for importlib.resources.files\n",
        "import sys\n",
        "\n",
        "if sys.version_info < (3, 9):\n",
        "    try:\n",
        "        import importlib.resources as _ir\n",
        "        # Requires the backport package: `pip install importlib_resources`\n",
        "        import importlib_resources as _backport\n",
        "        if not hasattr(_ir, \"files\"):\n",
        "            _ir.files = _backport.files\n",
        "            print(\"Patched importlib.resources.files using importlib_resources.\")\n",
        "    except ImportError as e:\n",
        "        print(\"WARNING: importlib_resources is not installed.\")\n",
        "        print(\"Install it in this environment with: pip install importlib_resources\")\n",
        "else:\n",
        "    # On Python >= 3.9, this shim is not needed but harmless\n",
        "    import importlib.resources as _ir\n",
        "\n",
        "print(\"Python version:\", sys.version)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Patched importlib.resources.files using importlib_resources.\n",
            "Python version: 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import pprint\n",
        "import google.generativeai as genai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Add project root to path\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Find the project root by walking up until we see pyproject.toml\n",
        "project_root = Path.cwd()\n",
        "while not (project_root / \"pyproject.toml\").exists() and project_root.parent != project_root:\n",
        "    project_root = project_root.parent\n",
        "\n",
        "# Add repo root and src/ to sys.path\n",
        "sys.path.insert(0, str(project_root))\n",
        "sys.path.insert(0, str(project_root / \"src\"))\n",
        "\n",
        "print(\"Project root:\", project_root)\n",
        "print(\"Python path entry added:\", project_root / \"src\")\n",
        "\n",
        "# Import the preprocessing module\n",
        "from mosaic.preprocessing.preprocessing import (\n",
        "    load_data,\n",
        "    basic_preprocess,\n",
        "    preprocess_with_local_llama,  # For local Llama model\n",
        "    preprocess_with_gemini_api,   # For Google Gemini API\n",
        "    compare_cleaning_results\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Preprocessing module loaded successfully\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\google\\api_core\\_python_version_support.py:246: FutureWarning: You are using a non-supported Python version (3.8.10). Google will not post any further updates to google.api_core supporting this Python version. Please upgrade to the latest Python version, or at least Python 3.10, and then update google.api_core.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "c:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\google\\auth\\__init__.py:52: FutureWarning: You are using a Python version 3.8 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
            "  warnings.warn(eol_message.format(\"3.8\"), FutureWarning)\n",
            "c:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\google\\oauth2\\__init__.py:38: FutureWarning: You are using a Python version 3.8 past its end of life. Google will update google-auth with critical bug fixes on a best-effort basis, but not with any other fixes or features. Please upgrade your Python version, and then update google-auth.\n",
            "  warnings.warn(eol_message.format(\"3.8\"), FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Project root: c:\\Users\\andre\\projects\\MOSAIC\n",
            "Python path entry added: c:\\Users\\andre\\projects\\MOSAIC\\src\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "c:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Preprocessing module loaded successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "notebook_dir = Path.cwd()\n",
        "project_root = notebook_dir.parent.parent\n",
        "DATA_DIR = project_root / \"DATA\"\n",
        "print(f\"DATA_DIR set to: {DATA_DIR}\")\n",
        "if not DATA_DIR.exists():\n",
        "    print(\"WARNING: DATA folder not found. Check your folder structure.\")\n",
        "else:\n",
        "    #print the available raw datasets in the DATA_DIR/raw folder\n",
        "    RAW_DIR = DATA_DIR / \"raw\"\n",
        "    PREPROC_DIR = DATA_DIR / \"preprocessed\"\n",
        "    available_datasets = [f.name for f in RAW_DIR.glob(\"*.csv\")]\n",
        "    print(f\"Available raw datasets: {available_datasets}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DATA_DIR set to: c:\\Users\\andre\\projects\\MOSAIC\\DATA\n",
            "Available raw datasets: ['meditation_reflections.csv', 'trial_200_topics.csv', 'trial_cleaned_raw.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DATASETS = {}\n",
        "\n",
        "if not DATA_DIR.exists():\n",
        "    print(\"WARNING: DATA folder not found. Check your folder structure.\")\n",
        "elif not RAW_DIR.exists():\n",
        "    print(f\"WARNING: 'raw' folder not found inside DATA. ({RAW_DIR})\")\n",
        "else:\n",
        "    # Find all CSVs that end with '_raw.csv'\n",
        "    raw_files = list(RAW_DIR.glob(\"*_raw.csv\"))\n",
        "    \n",
        "    print(f\"Available raw datasets: {[f.name for f in raw_files]}\")\n",
        "\n",
        "    for file_path in raw_files:\n",
        "        filename = file_path.name\n",
        "        \n",
        "        # Extract the name (remove '_raw.csv' from the end)\n",
        "        dataset_name = filename.rsplit('_raw.csv', 1)[0]\n",
        "        \n",
        "        # Build the dictionary entry dynamically\n",
        "        DATASETS[dataset_name] = {\n",
        "            'input': filename,\n",
        "            'output_api': f\"{dataset_name}_cleaned_API.csv\",\n",
        "            'output_local': f\"{dataset_name}_cleaned_llama.csv\"\n",
        "        }\n",
        "\n",
        "    print(\"\\n--- Generated Configuration ---\")\n",
        "    pprint.pprint(DATASETS)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available raw datasets: ['meditation_reflections_raw.csv', 'trial_cleaned_raw.csv']\n",
            "\n",
            "--- Generated Configuration ---\n",
            "{'meditation_reflections': {'input': 'meditation_reflections_raw.csv',\n",
            "                            'output_api': 'meditation_reflections_cleaned_API.csv',\n",
            "                            'output_local': 'meditation_reflections_cleaned_llama.csv'},\n",
            " 'trial_cleaned': {'input': 'trial_cleaned_raw.csv',\n",
            "                   'output_api': 'trial_cleaned_cleaned_API.csv',\n",
            "                   'output_local': 'trial_cleaned_cleaned_llama.csv'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Select Dataset and Preprocessing Method\n",
        "\n",
        "### WORKFLOW FOR COMPARING MODELS:\n",
        "1. Set `NUM_SAMPLES = 5` (or 10) to test\n",
        "2. Run each method on the same sample\n",
        "3. Compare results in Step 4\n",
        "4. Choose best method\n",
        "5. Set `NUM_SAMPLES = None` to run on full data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ============================================\n",
        "#  SELECT DATASET AND METHOD\n",
        "# ============================================\n",
        "\n",
        "# Choose dataset (see above available)\n",
        "DATASET_CHOICE = 'meditation_reflections'\n",
        "\n",
        "# Choose preprocessing method:\n",
        "#   'local_llama'  → Local Llama 3 model (needs GPU: Metal/CUDA)\n",
        "#   'gemini_api'   → Google Gemini API (needs GOOGLE_API_KEY)\n",
        "METHOD_CHOICE = 'gemini_api'\n",
        "\n",
        "# FOR TESTING: Set to a number (5, 10, etc) or None for full dataset\n",
        "# TIP: Test with 5-10 samples first to compare methods, then set to None\n",
        "NUM_SAMPLES = 5\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"CONFIGURATION\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Dataset:        {DATASET_CHOICE}\")\n",
        "print(f\"Method:         {METHOD_CHOICE}\")\n",
        "print(f\"Samples:        {NUM_SAMPLES if NUM_SAMPLES else 'ALL (FULL DATASET)'}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "if NUM_SAMPLES:\n",
        "    print(f\"\\nRunning in TEST mode with {NUM_SAMPLES} samples\")\n",
        "    print(f\"  (Good for checking if everything works before full run)\")\n",
        "else:\n",
        "    print(f\"\\nRunning on FULL DATASET\")\n",
        "    print(f\"  (This may take a while)\")\n",
        "\n",
        "\n",
        "if METHOD_CHOICE == 'gemini_api':\n",
        "    # Load .env file for API key\n",
        "    load_dotenv()\n",
        "    api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
        "    \n",
        "    if not api_key:\n",
        "        print(\"Error: GOOGLE_API_KEY not found in .env file.\")\n",
        "        sys.exit(1)\n",
        "    \n",
        "    # Configure Gemini\n",
        "    genai.configure(api_key=api_key)\n",
        "    print(\"Google Gemini API configured successfully.\")\n",
        "    print(f\"API Key found: {api_key[:5]}...*****\")\n",
        "    print(\"\\n--- Available Gemini Models (generateContent) ---\")\n",
        "    \n",
        "    # List Models\n",
        "    try:\n",
        "        found_any = False\n",
        "        for m in genai.list_models():\n",
        "            # Only show models that can generate text (chat models)\n",
        "            if 'generateContent' in m.supported_generation_methods:\n",
        "                print(f\"  • {m.name}\")\n",
        "                found_any = True\n",
        "        \n",
        "        if not found_any:\n",
        "            print(\"No models found. Check your API key permissions.\")\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error listing models: {e}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "CONFIGURATION\n",
            "============================================================\n",
            "Dataset:        meditation_reflections\n",
            "Method:         gemini_api\n",
            "Samples:        5\n",
            "============================================================\n",
            "\n",
            "Running in TEST mode with 5 samples\n",
            "  (Good for checking if everything works before full run)\n",
            "Google Gemini API configured successfully.\n",
            "API Key found: AIzaS...*****\n",
            "\n",
            "--- Available Gemini Models (generateContent) ---\n",
            "No models found. Check your API key permissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Build file paths\n",
        "dataset_config = DATASETS[DATASET_CHOICE]\n",
        "input_path = os.path.join(RAW_DIR, dataset_config['input'])\n",
        "\n",
        "# Load data\n",
        "df = load_data(input_path, text_column='reflection_answer', remove_na=True)\n",
        "\n",
        "if df is not None:\n",
        "    print(f\"\\nSuccessfully loaded {len(df)} records\")\n",
        "    print(f\"DataFrame shape: {df.shape}\")\n",
        "    print(f\"Columns: {df.columns.tolist()}\")\n",
        "    print(f\"\\nFirst 5 rows (preview):\")\n",
        "    display(df.head(5))\n",
        "else:\n",
        "    print(\"Failed to load data. Check file path and try again.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 202 reports from meditation_reflections_raw.csv\n",
            "\n",
            "Successfully loaded 202 records\n",
            "DataFrame shape: (202, 1)\n",
            "Columns: ['reflection_answer']\n",
            "\n",
            "First 5 rows (preview):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reflection_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I felt anchored in the physical. That groundin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I noticed the quality of contact between my ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There was a sense of the body as alive and res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The boundaries between self and environment bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I lost track of how long I had been sitting. T...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   reflection_answer\n",
              "0  I felt anchored in the physical. That groundin...\n",
              "1  I noticed the quality of contact between my ha...\n",
              "2  There was a sense of the body as alive and res...\n",
              "3  The boundaries between self and environment bl...\n",
              "4  I lost track of how long I had been sitting. T..."
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Sentence-split only: cut each row into individual sentences, one row per sentence\n",
        "# Run this cell INSTEAD of Step 3 to bypass Gemini/Llama\n",
        "from mosaic.preprocessing.preprocessing import split_sentences\n",
        "\n",
        "if df is None:\n",
        "    print(\"No data loaded. Run Step 2 first.\")\n",
        "else:\n",
        "    df_slice = df.head(NUM_SAMPLES).copy() if NUM_SAMPLES else df.copy()\n",
        "    texts = df_slice[\"reflection_answer\"].astype(str).tolist()\n",
        "    sentences, doc_map = split_sentences(texts)\n",
        "    filtered = [(s.strip(), doc_map[i]) for i, s in enumerate(sentences) if s.strip()]\n",
        "    df_to_process = pd.DataFrame({\n",
        "        \"reflection_answer\": [texts[i] for _, i in filtered],\n",
        "        \"cleaned_reflection\": [s for s, _ in filtered],\n",
        "    })\n",
        "    print(f\"Sentence-split complete: {len(df_slice)} rows -> {len(df_to_process)} sentences\")\n",
        "    print(f\"Columns: {df_to_process.columns.tolist()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Run Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if df is None:\n",
        "    print(\"No data loaded. Run Step 2 first.\")\n",
        "else:\n",
        "    df_to_process = df.head(NUM_SAMPLES).copy() if NUM_SAMPLES else df.copy()\n",
        "    \n",
        "    # ============================================\n",
        "    # LOCAL LLAMA METHOD (using Llama 3)\n",
        "    # ============================================\n",
        "    if METHOD_CHOICE == 'local_llama':\n",
        "        output_path = os.path.join(PREPROC_DIR, dataset_config['output_local'])\n",
        "        if NUM_SAMPLES:\n",
        "            output_path = output_path.replace('.csv', f'_{NUM_SAMPLES}_test.csv')\n",
        "        \n",
        "        df_to_process = preprocess_with_local_llama(\n",
        "            csv_path=input_path,\n",
        "            output_path=output_path,\n",
        "            text_column='reflection_answer',\n",
        "            num_samples=NUM_SAMPLES\n",
        "        )\n",
        "    \n",
        "    # ============================================\n",
        "    # GEMINI API METHOD\n",
        "    # ============================================\n",
        "    elif METHOD_CHOICE == 'gemini_api':\n",
        "        print(\"Running GEMINI API preprocessing...\")\n",
        "        print(f\"(Using Google Gemini with batch processing)\\n\")\n",
        "        \n",
        "        output_path = os.path.join(PREPROC_DIR, dataset_config['output_api'])\n",
        "        if NUM_SAMPLES:\n",
        "            output_path = output_path.replace('.csv', f'_{NUM_SAMPLES}_test.csv')\n",
        "        \n",
        "        df_to_process = preprocess_with_gemini_api(\n",
        "            csv_path=input_path,\n",
        "            output_path=output_path,\n",
        "            text_column='reflection_answer',\n",
        "            batch_size=20,\n",
        "            num_samples=NUM_SAMPLES,\n",
        "            model_name=\"gemini-2.5-flash-lite\"\n",
        "        )\n",
        "        print(f\"\\nGemini API preprocessing complete\")\n",
        "    \n",
        "    else:\n",
        "        print(f\"Unknown method: {METHOD_CHOICE}\")\n",
        "        print(f\"Choose from: 'local_llama', 'gemini_api'\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running GEMINI API preprocessing...\n",
            "(Using Google Gemini with batch processing)\n",
            "\n",
            "[OK] Using specified Gemini model: gemini-2.5-flash-lite\n",
            "\n",
            "================================================================================\n",
            "GEMINI API PREPROCESSING\n",
            "================================================================================\n",
            "Input file: meditation_reflections_raw.csv\n",
            "Model: gemini-2.5-flash-lite\n",
            "Delay between texts: 2s\n",
            "Max text length: No limit (process all reports)\n",
            "Processing: 5 reports\n",
            "\n",
            "================================================================================\n",
            "PRE-FLIGHT CHECK: Gemini API\n",
            "================================================================================\n",
            "\n",
            "MODEL:\n",
            "  Selected model:        gemini-2.0-flash-lite (default)\n",
            "  Rate limit:            10 requests/min, 1000/day\n",
            "\n",
            "REPORT STATISTICS:\n",
            "  Total reports:         5\n",
            "  Total characters:      440\n",
            "  Average length:        88 chars\n",
            "  Longest report:        101 chars\n",
            "\n",
            "API SETTINGS:\n",
            "  Delay between calls:   2s\n",
            "\n",
            "TIME ESTIMATES:\n",
            "  Estimated time:        ~0.3 minutes\n",
            "\n",
            "================================================================================\n",
            "QUOTA ANALYSIS:\n",
            "================================================================================\n",
            "  Model limit:           10 requests/minute\n",
            "  Your effective rate:   ~15.0 requests/minute\n",
            "\n",
            "  WARNING: With 2s delay, you may hit quota\n",
            "\n",
            "  RECOMMENDATIONS:\n",
            "    - Use --delay 7 or higher\n",
            "    - Errors will be marked and can be retried with --retry-failed\n",
            "\n",
            "================================================================================\n",
            "[OK] Ready to process 5 reports!\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Processing 5 texts individually...\n",
            "Estimated time: ~0.3 minutes\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Gemini API: 100%|██████████| 5/5 [00:23<00:00,  4.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SUMMARY\n",
            "================================================================================\n",
            "Total reports: 5\n",
            "Successfully processed: 5\n",
            "Errors: 0\n",
            "Skipped (too long): 0\n",
            "Output saved to: c:\\Users\\andre\\projects\\MOSAIC\\DATA\\preprocessed\\meditation_reflections_cleaned_API_5_test.csv\n",
            "================================================================================\n",
            "\n",
            "\n",
            "Gemini API preprocessing complete\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Review Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if df_to_process is not None and 'cleaned_reflection' in df_to_process.columns:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"RESULTS SUMMARY\")\n",
        "    print(f\"{'='*80}\")\n",
        "    print(f\"Total processed: {len(df_to_process)}\")\n",
        "    print(f\"Columns: {df_to_process.columns.tolist()}\")\n",
        "    print(f\"\\nDataFrame Info:\")\n",
        "    print(df_to_process.info())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "RESULTS SUMMARY\n",
            "================================================================================\n",
            "Total processed: 5\n",
            "Columns: ['reflection_answer', 'cleaned_reflection']\n",
            "\n",
            "DataFrame Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5 entries, 0 to 4\n",
            "Data columns (total 2 columns):\n",
            " #   Column              Non-Null Count  Dtype \n",
            "---  ------              --------------  ----- \n",
            " 0   reflection_answer   5 non-null      object\n",
            " 1   cleaned_reflection  5 non-null      object\n",
            "dtypes: object(2)\n",
            "memory usage: 208.0+ bytes\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Full Results Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Show all rows for review\n",
        "print(f\"\\nAll {len(df_to_process)} processed records:\")\n",
        "display(df_to_process)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "All 5 processed records:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reflection_answer</th>\n",
              "      <th>cleaned_reflection</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I felt anchored in the physical. That groundin...</td>\n",
              "      <td>I felt anchored in the physical. That groundin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I noticed the quality of contact between my ha...</td>\n",
              "      <td>I noticed the quality of contact between my ha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>There was a sense of the body as alive and res...</td>\n",
              "      <td>There was a sense of the body as alive and res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The boundaries between self and environment bl...</td>\n",
              "      <td>The boundaries between self and environment bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I lost track of how long I had been sitting. T...</td>\n",
              "      <td>I lost track of how long I had been sitting. T...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   reflection_answer  \\\n",
              "0  I felt anchored in the physical. That groundin...   \n",
              "1  I noticed the quality of contact between my ha...   \n",
              "2  There was a sense of the body as alive and res...   \n",
              "3  The boundaries between self and environment bl...   \n",
              "4  I lost track of how long I had been sitting. T...   \n",
              "\n",
              "                                  cleaned_reflection  \n",
              "0  I felt anchored in the physical. That groundin...  \n",
              "1  I noticed the quality of contact between my ha...  \n",
              "2  There was a sense of the body as alive and res...  \n",
              "3  The boundaries between self and environment bl...  \n",
              "4  I lost track of how long I had been sitting. T...  "
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Side-by-Side Comparison (Original vs Cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if 'reflection_answer' in df_to_process.columns and 'cleaned_reflection' in df_to_process.columns:\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(\"ORIGINAL vs CLEANED COMPARISON\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "    \n",
        "    for i in range(min(5, len(df_to_process))):\n",
        "        print(f\"[Record {i+1}]\")\n",
        "        print(f\"ORIGINAL:\")\n",
        "        original = str(df_to_process['reflection_answer'].iloc[i])\n",
        "        print(f\"  {original[:200]}...\" if len(original) > 200 else f\"  {original}\")\n",
        "        print(f\"\\nCLEANED:\")\n",
        "        cleaned = str(df_to_process['cleaned_reflection'].iloc[i])\n",
        "        print(f\"  {cleaned[:200]}...\" if len(cleaned) > 200 else f\"  {cleaned}\")\n",
        "        print(f\"{'-'*80}\\n\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "ORIGINAL vs CLEANED COMPARISON\n",
            "================================================================================\n",
            "\n",
            "[Record 1]\n",
            "ORIGINAL:\n",
            "  I felt anchored in the physical. That grounding allowed the mind to settle.\n",
            "\n",
            "CLEANED:\n",
            "  I felt anchored in the physical. That grounding allowed the mind to settle.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[Record 2]\n",
            "ORIGINAL:\n",
            "  I noticed the quality of contact between my hands. Were they touching? The sensation was ambiguous.\n",
            "\n",
            "CLEANED:\n",
            "  I noticed the quality of contact between my hands. Were they touching? The sensation was ambiguous.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[Record 3]\n",
            "ORIGINAL:\n",
            "  There was a sense of the body as alive and responsive. It was not inert.\n",
            "\n",
            "CLEANED:\n",
            "  There was a sense of the body as alive and responsive. It was not inert.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[Record 4]\n",
            "ORIGINAL:\n",
            "  The boundaries between self and environment blurred. I was not sure where I ended and the room began.\n",
            "\n",
            "CLEANED:\n",
            "  The boundaries between self and environment blurred. I was not sure where I ended and the room began.\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "[Record 5]\n",
            "ORIGINAL:\n",
            "  I lost track of how long I had been sitting. The usual markers of time did not seem to apply.\n",
            "\n",
            "CLEANED:\n",
            "  I lost track of how long I had been sitting. The usual markers of time did not seem to apply.\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if 'reflection_answer' in df_to_process.columns and 'cleaned_reflection' in df_to_process.columns:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TEXT LENGTH STATISTICS\")\n",
        "    print(\"=\"*80 + \"\\n\")\n",
        "    \n",
        "    original_lengths = df_to_process['reflection_answer'].astype(str).str.len()\n",
        "    cleaned_lengths = df_to_process['cleaned_reflection'].astype(str).str.len()\n",
        "    \n",
        "    print(f\"Original texts:\")\n",
        "    print(f\"  Mean length: {original_lengths.mean():.0f} characters\")\n",
        "    print(f\"  Min length: {original_lengths.min()} characters\")\n",
        "    print(f\"  Max length: {original_lengths.max()} characters\")\n",
        "    \n",
        "    print(f\"\\nCleaned texts:\")\n",
        "    print(f\"  Mean length: {cleaned_lengths.mean():.0f} characters\")\n",
        "    print(f\"  Min length: {cleaned_lengths.min()} characters\")\n",
        "    print(f\"  Max length: {cleaned_lengths.max()} characters\")\n",
        "    \n",
        "    print(f\"\\nDifference (cleaned - original):\")\n",
        "    diff = (cleaned_lengths - original_lengths)\n",
        "    print(f\"  Mean: {diff.mean():.0f} characters\")\n",
        "    print(f\"  Min: {diff.min()} characters\")\n",
        "    print(f\"  Max: {diff.max()} characters\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TEXT LENGTH STATISTICS\n",
            "================================================================================\n",
            "\n",
            "Original texts:\n",
            "  Mean length: 88 characters\n",
            "  Min length: 72 characters\n",
            "  Max length: 101 characters\n",
            "\n",
            "Cleaned texts:\n",
            "  Mean length: 88 characters\n",
            "  Min length: 72 characters\n",
            "  Max length: 101 characters\n",
            "\n",
            "Difference (cleaned - original):\n",
            "  Mean: 0 characters\n",
            "  Min: 0 characters\n",
            "  Max: 0 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Run Full Dataset (when satisfied)\n",
        "\n",
        "After testing with `NUM_SAMPLES = 5` and reviewing results above:\n",
        "\n",
        "1. **If results look good**: Uncomment code below\n",
        "2. **Change `NUM_SAMPLES = 5` to `NUM_SAMPLES = None`**\n",
        "3. **Re-run from Step 1 through Step 3** to process full dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "print(\"\\nTo run the full dataset:\")\n",
        "print(\"  1. Go to Step 1 (Select Dataset and Method)\")\n",
        "print(\"  2. Change NUM_SAMPLES = 5 to NUM_SAMPLES = None\")\n",
        "print(\"  3. Run cells in Steps 1 through 3 again\")\n",
        "print(\"  4. Review final results in Step 4\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "To run the full dataset:\n",
            "  1. Go to Step 1 (Select Dataset and Method)\n",
            "  2. Change NUM_SAMPLES = 5 to NUM_SAMPLES = None\n",
            "  3. Run cells in Steps 1 through 3 again\n",
            "  4. Review final results in Step 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Run basic (basic preprocessing and divide into sentences)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_to_process['cleaned_reflection']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'reflection_answer'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'reflection_answer'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_to_process\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreflection_answer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'reflection_answer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "print(\"Running BASIC preprocessing...\")\n",
        "texts = df_to_process['cleaned_reflection'].tolist()\n",
        "df_to_process = basic_preprocess(texts, split_into_sentences=True, min_words=2)\n",
        "print(f\"Basic preprocessing complete\")\n",
        "\n",
        "#show the first 5 rows after basic preprocessing\n",
        "print(f\"\\nFirst 5 rows after BASIC preprocessing:\")\n",
        "display(df_to_process.head(5))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running BASIC preprocessing...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'reflection_answer'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'reflection_answer'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning BASIC preprocessing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[43mdf_to_process\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreflection_answer\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      3\u001b[0m df_to_process \u001b[38;5;241m=\u001b[39m basic_preprocess(texts, split_into_sentences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, min_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBasic preprocessing complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[1;32mc:\\Users\\andre\\projects\\MOSAIC\\.mosavenv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'reflection_answer'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".mosavenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}